# Clustering-using-K-Means-and-Bradley-Fayyad-Reina-BFR-algorithm
 Implementation of K-Means and Bradley-Fayyad-Reina (BFR) algorithm from scratch without using any library.
 
# **Introduction:**

## **Clustering:** 
  
  ◆ Clustering is the task of dividing the population or data points into a number of groups such that data points in the same groups        are more similar to other data points in the same group than those in other groups. In simple words, the aim is to segregate groups      with similar traits and assign them into clusters.
  
  ◆ Clustering is an unsupervised learning algorithm and an important task, that help us find more useful insights from data as we are      aware that most of the data in the real-world scenario is unlabelled.
  
  ◆ We are aware about the K-means clustering algorithm for the clustering of the data points but it is not productive for the large       datasets as it takes more memory and time. Thats why Bradley-Fayyad-Reina Algorithm came into existence.
  
  

## **BFR [Bradley-Fayyad-Reina]:**
  
  ◆ The BFR algorithm, named after its inventors Bradley, Fayyad and Reina, is a variant of k-means algorithm that is designed to           cluster data in a high-dimensional Euclidean space. 
  
  ◆ It is	a	variant	of	k-means	designed	to handle	very	large (disk-resident)	data	sets. However, K-means is used as an main memory         algorithm for generating initial clustering of data points. By making use of Bradley-Fayyad-Reina Algorithm there is a drastic           reduction in memory consumed and time taken for clustering of data points.

# **Dataset Description:**

The datasets used are synthetic datasets. Since the BFR algorithm has a strong assumption that the clusters are normally distributed with independent dimensions, datasets are generated by initializing some random centroids and creating data points with these centroids and some standard deviations to form the clusters. In this there are also some added data points as outliers. The “cluster” number of these outliers is represented by -1 (i.e., no clusters). Figure 1 shows an example of the data points (in CSV format). The first column is the data point index. The rest columns represent the features/dimensions of the data point.

The code written is tested on eight different types of datasets which vary by many characteristics(some has 5lakh datapoints, more than 50 feautures, more number of outliers and all possible cases of datasets) and **the code worked well on all these datasets with an NMI of more than 0.8 for all cases and ran in less than 150 seconds for all the cases**. 

# **Approach:**

* Firstly, we will be using K-means clustering technique for initialization of clusters on a single chunk of file(main-memory algorithm).
  ## **K-Means++ Algorithm:** 
  * But as we are aware that the dataset consists of outliers, and K-means is highly sensitive to outliers.
  * In K-means, we will be randomly initialising centroids for clustering of data points, the probability of choosing an outlier as a       centroid is higher in some test cases which leaves a cluster with a single data point after iterations on first chunk.
  * In order to avoid this, we used Kmeans++ algorithm for initialization of clusters, where the outliers are removed from dataset by       calculating euclidean distance with less number of iterations keeping run time in mind.
  * Now the filtered datapoints are sent to K-means algorithm for initialization of clusters using only first chunk of data points.




 
